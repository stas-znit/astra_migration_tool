#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö.

–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–¥—ã –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –∏–∑ –ª–æ–≥–æ–≤ –∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏, 
–ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python analyze_migration_errors.py [--log-file LOG_FILE] [--state-file STATE_FILE] [--include-warnings]
"""

import json
import re
import argparse
import sys
from collections import defaultdict, Counter
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(str(Path(__file__).parent.parent))

try:
    from src.errors.error_codes import MigrationErrorCodes, get_error_by_code, ErrorCategory
except ImportError:
    print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å –∫–æ–¥–æ–≤ –æ—à–∏–±–æ–∫")
    print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—â–µ–Ω –∏–∑ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞")
    sys.exit(1)


class MigrationErrorAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –º–∏–≥—Ä–∞—Ü–∏–∏"""
    
    def __init__(self, include_warnings: bool = True):
        self.errors_found = []
        self.warnings_found = []
        self.include_warnings = include_warnings
        
        self.error_patterns = {
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–¥–æ–≤ –æ—à–∏–±–æ–∫ –∏–∑ –ª–æ–≥–æ–≤
            'error_code': re.compile(r'\[([A-Z]+_\d+)\]'),
            'timestamp': re.compile(r'(\d{4}-\d{2}-\d{2}[T ]\d{2}:\d{2}:\d{2})'),
            'severity_level': re.compile(r'(ERROR|WARNING|CRITICAL|INFO)', re.IGNORECASE),
            'user_context': re.compile(r'–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å[–∞|–µ]?\s+([a-zA-Z0-9._@-]+)', re.IGNORECASE),
            'file_context': re.compile(r'—Ñ–∞–π–ª[–∞|–µ]?\s+([^\s]+\.[a-zA-Z0-9]+)', re.IGNORECASE),
            'function_context': re.compile(r'—Ñ—É–Ω–∫—Ü–∏[—è|–∏]\s+([a-zA-Z0-9_]+)', re.IGNORECASE),
            'path_context': re.compile(r'–ø—É—Ç[—å|–∏]\s+([/\\][^\s]+)', re.IGNORECASE)
        }
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö WARNING —Å–æ–æ–±—â–µ–Ω–∏–π Python
        self.warning_patterns = {
            'deprecation': re.compile(r'DeprecationWarning', re.IGNORECASE),
            'resource': re.compile(r'ResourceWarning', re.IGNORECASE),
            'runtime': re.compile(r'RuntimeWarning', re.IGNORECASE),
            'user': re.compile(r'UserWarning', re.IGNORECASE),
            'future': re.compile(r'FutureWarning', re.IGNORECASE)
        }
    
    def analyze_log_file(self, log_file_path: str):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –ª–æ–≥–æ–≤ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –º–∏–≥—Ä–∞—Ü–∏–∏"""
        try:
            with open(log_file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            print(f"üìã –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª –ª–æ–≥–æ–≤: {log_file_path}")
            print(f"üìÑ –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –≤ –ª–æ–≥–µ: {len(lines)}")
            
            for line_num, line in enumerate(lines, 1):
                self._parse_log_line(line, line_num)
                
        except FileNotFoundError:
            print(f"‚ùå –§–∞–π–ª –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {log_file_path}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –ª–æ–≥–æ–≤: {e}")
    
    def analyze_state_file(self, state_file_path: str):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏"""
        try:
            with open(state_file_path, 'r', encoding='utf-8') as f:
                state_data = json.load(f)
            
            print(f"üìã –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è: {state_file_path}")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –æ—à–∏–±–∫–∏
            global_state = state_data.get('global', {})
            if 'last_error' in global_state and global_state['last_error']:
                self._parse_state_error(global_state['last_error'], 'global')
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
            if 'last_warning' in global_state and global_state['last_warning']:
                self._parse_state_warning(global_state['last_warning'], 'global')
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º
            users_state = state_data.get('users', {})
            failed_users = [user for user, status in users_state.items() if status == 'failed']
            warning_users = [user for user, status in users_state.items() if status == 'warning']
            
            if failed_users:
                print(f"üë• –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å –æ—à–∏–±–∫–∞–º–∏ –º–∏–≥—Ä–∞—Ü–∏–∏: {len(failed_users)}")
                for user in failed_users:
                    print(f"   ‚Ä¢ {user}")
            
            if warning_users and self.include_warnings:
                print(f"‚ö†Ô∏è  –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏: {len(warning_users)}")
                for user in warning_users:
                    print(f"   ‚Ä¢ {user}")
            
            # –ò—â–µ–º —Å–≤–æ–¥–∫—É –æ—à–∏–±–æ–∫, –µ—Å–ª–∏ –µ—Å—Ç—å
            if 'error_summary' in global_state:
                self._parse_error_summary(global_state['error_summary'])
                
        except FileNotFoundError:
            print(f"‚ùå –§–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω: {state_file_path}")
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON —Ñ–∞–π–ª–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}")
    
    def _parse_log_line(self, line: str, line_num: int):
        """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É –ª–æ–≥–∞ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π"""
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏
        severity_match = self.error_patterns['severity_level'].search(line)
        severity = severity_match.group(1).upper() if severity_match else 'UNKNOWN'
        
        # –ò—â–µ–º –∫–æ–¥ –æ—à–∏–±–∫–∏
        error_match = self.error_patterns['error_code'].search(line)
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–æ–¥ –æ—à–∏–±–∫–∏ - —ç—Ç–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞/–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
        if error_match:
            error_code = error_match.group(1)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            parsed_info = self._extract_context_info(line, line_num, severity)
            parsed_info['code'] = error_code
            parsed_info['source'] = 'log'
            
            # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –ø–æ severity
            if severity in ['ERROR', 'CRITICAL']:
                self.errors_found.append(parsed_info)
            elif severity == 'WARNING' and self.include_warnings:
                self.warnings_found.append(parsed_info)
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–¥–∞ –æ—à–∏–±–∫–∏, –Ω–æ –µ—Å—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ WARNING –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        elif self.include_warnings and severity == 'WARNING':
            warning_type = self._identify_warning_type(line)
            if warning_type:
                parsed_info = self._extract_context_info(line, line_num, severity)
                parsed_info['code'] = f'PYTHON_{warning_type.upper()}'
                parsed_info['warning_type'] = warning_type
                parsed_info['source'] = 'log'
                self.warnings_found.append(parsed_info)
    
    def _extract_context_info(self, line: str, line_num: int, severity: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Å—Ç—Ä–æ–∫–∏ –ª–æ–≥–∞"""
        timestamp_match = self.error_patterns['timestamp'].search(line)
        user_match = self.error_patterns['user_context'].search(line)
        file_match = self.error_patterns['file_context'].search(line)
        function_match = self.error_patterns['function_context'].search(line)
        path_match = self.error_patterns['path_context'].search(line)
        
        return {
            'line_number': line_num,
            'severity': severity,
            'timestamp': timestamp_match.group(1) if timestamp_match else None,
            'user': user_match.group(1) if user_match else None,
            'file': file_match.group(1) if file_match else None,
            'function': function_match.group(1) if function_match else None,
            'path': path_match.group(1) if path_match else None,
            'full_line': line.strip()
        }
    
    def _identify_warning_type(self, line: str) -> Optional[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è Python"""
        for warning_type, pattern in self.warning_patterns.items():
            if pattern.search(line):
                return warning_type
        return None
    
    def _parse_state_error(self, error_data: Dict[str, Any], context: str):
        """–ü–∞—Ä—Å–∏—Ç –æ—à–∏–±–∫—É –∏–∑ —Ñ–∞–π–ª–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        error_info = {
            'code': error_data.get('code', 'UNKNOWN'),
            'category': error_data.get('category', 'UNKNOWN'),
            'description': error_data.get('description', ''),
            'details': error_data.get('details', ''),
            'severity': error_data.get('severity', 'ERROR'),
            'timestamp': error_data.get('timestamp', ''),
            'context': context,
            'source': 'state'
        }
        
        if 'exception' in error_data:
            error_info['exception_type'] = error_data['exception'].get('type', '')
            error_info['exception_message'] = error_data['exception'].get('message', '')
        
        self.errors_found.append(error_info)
    
    def _parse_state_warning(self, warning_data: Dict[str, Any], context: str):
        """–ü–∞—Ä—Å–∏—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –∏–∑ —Ñ–∞–π–ª–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        if not self.include_warnings:
            return
            
        warning_info = {
            'code': warning_data.get('code', 'UNKNOWN'),
            'category': warning_data.get('category', 'UNKNOWN'),
            'description': warning_data.get('description', ''),
            'details': warning_data.get('details', ''),
            'severity': 'WARNING',
            'timestamp': warning_data.get('timestamp', ''),
            'context': context,
            'source': 'state'
        }
        
        self.warnings_found.append(warning_info)
    
    def _parse_error_summary(self, summary_data: Dict[str, Any]):
        """–ü–∞—Ä—Å–∏—Ç —Å–≤–æ–¥–∫—É –æ—à–∏–±–æ–∫"""
        print(f"\nüìä –°–≤–æ–¥–∫–∞ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è:")
        print(f"   –í—Å–µ–≥–æ –æ—à–∏–±–æ–∫: {summary_data.get('total_errors', 0)}")
        
        by_category = summary_data.get('by_category', {})
        for category, count in by_category.items():
            if count > 0:
                print(f"   {category}: {count}")
    
    def generate_report(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –æ–± –æ—à–∏–±–∫–∞—Ö –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è—Ö"""
        total_issues = len(self.errors_found) + len(self.warnings_found)
        
        if total_issues == 0:
            print("\n‚úÖ –û—à–∏–±–∫–∏ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            return
        
        print(f"\nüìä –ê–ù–ê–õ–ò–ó –û–®–ò–ë–û–ö –ò –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ô –ú–ò–ì–†–ê–¶–ò–ò")
        print("=" * 60)
        print(f"–ù–∞–π–¥–µ–Ω–æ –æ—à–∏–±–æ–∫: {len(self.errors_found)}")
        if self.include_warnings:
            print(f"–ù–∞–π–¥–µ–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {len(self.warnings_found)}")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏
        if self.errors_found:
            self._analyze_errors()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        if self.warnings_found and self.include_warnings:
            self._analyze_warnings()
        
        # –í—Ä–µ–º–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self._analyze_timeline()
        
        # –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
        self._analyze_problematic_users()
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        self._generate_recommendations()
    
    def _analyze_errors(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—à–∏–±–∫–∏"""
        print(f"\n‚ùå –ê–ù–ê–õ–ò–ó –û–®–ò–ë–û–ö:")
        print("-" * 30)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–¥–∞–º –æ—à–∏–±–æ–∫
        error_codes = [err['code'] for err in self.errors_found]
        code_counts = Counter(error_codes)
        
        print(f"üî¢ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–¥–∞–º –æ—à–∏–±–æ–∫:")
        for code, count in code_counts.most_common():
            error_def = get_error_by_code(code)
            if error_def:
                print(f"   {code}: {count} —Ä–∞–∑ - {error_def.description}")
            else:
                print(f"   {code}: {count} —Ä–∞–∑ - (–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–æ–¥)")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        categories = defaultdict(int)
        severity_counts = defaultdict(int)
        
        for error in self.errors_found:
            error_def = get_error_by_code(error['code'])
            if error_def:
                categories[error_def.category.value] += 1
            else:
                categories['UNKNOWN'] += 1
            severity_counts[error.get('severity', 'ERROR')] += 1
        
        print(f"\nüìÅ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –æ—à–∏–±–æ–∫:")
        for category, count in sorted(categories.items()):
            print(f"   {category}: {count}")
        
        print(f"\nüö® –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—Ä–æ–≤–Ω—é –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏:")
        for severity, count in sorted(severity_counts.items()):
            icon = "üî¥" if severity == "CRITICAL" else "üü†" if severity == "ERROR" else "üü°"
            print(f"   {icon} {severity}: {count}")
    
    def _analyze_warnings(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è"""
        print(f"\n‚ö†Ô∏è  –ê–ù–ê–õ–ò–ó –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ô:")
        print("-" * 30)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–¥–∞–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
        warning_codes = [warn['code'] for warn in self.warnings_found]
        code_counts = Counter(warning_codes)
        
        print(f"üî¢ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–¥–∞–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π:")
        for code, count in code_counts.most_common():
            if code.startswith('PYTHON_'):
                warning_type = code.replace('PYTHON_', '').lower()
                print(f"   {code}: {count} —Ä–∞–∑ - {warning_type} –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ Python")
            else:
                warning_def = get_error_by_code(code)
                if warning_def:
                    print(f"   {code}: {count} —Ä–∞–∑ - {warning_def.description}")
                else:
                    print(f"   {code}: {count} —Ä–∞–∑ - (–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–æ–¥)")
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø–∞–º
        warning_types = defaultdict(int)
        for warning in self.warnings_found:
            if 'warning_type' in warning:
                warning_types[warning['warning_type']] += 1
            else:
                warning_types['migration'] += 1
        
        if warning_types:
            print(f"\nüìã –¢–∏–ø—ã –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π:")
            for warn_type, count in sorted(warning_types.items()):
                print(f"   {warn_type}: {count}")
    
    def _analyze_timeline(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        all_issues = self.errors_found + (self.warnings_found if self.include_warnings else [])
        timestamps = [issue.get('timestamp') for issue in all_issues if issue.get('timestamp')]
        
        if timestamps:
            print(f"\n‚è∞ –í—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω –ø—Ä–æ–±–ª–µ–º:")
            print(f"   –ü–µ—Ä–≤–∞—è: {min(timestamps)}")
            print(f"   –ü–æ—Å–ª–µ–¥–Ω—è—è: {max(timestamps)}")
            
            # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —á–∞—Å–∞–º –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –ø–∏–∫–æ–≤
            hour_counts = defaultdict(int)
            for ts in timestamps:
                try:
                    hour = ts.split('T')[1][:2] if 'T' in ts else ts.split(' ')[1][:2]
                    hour_counts[hour] += 1
                except:
                    continue
            
            if hour_counts:
                peak_hour = max(hour_counts.items(), key=lambda x: x[1])
                print(f"   –ü–∏–∫ –ø—Ä–æ–±–ª–µ–º: {peak_hour[0]}:00 ({peak_hour[1]} —Å–æ–±—ã—Ç–∏–π)")
    
    def _analyze_problematic_users(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
        all_issues = self.errors_found + (self.warnings_found if self.include_warnings else [])
        users = [issue.get('user') for issue in all_issues if issue.get('user')]
        
        if users:
            user_counts = Counter(users)
            print(f"\nüë• –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–æ–±–ª–µ–º:")
            for user, count in user_counts.most_common(5):
                user_errors = len([e for e in self.errors_found if e.get('user') == user])
                user_warnings = len([w for w in self.warnings_found if w.get('user') == user]) if self.include_warnings else 0
                
                status = "‚ùå" if user_errors > 0 else "‚ö†Ô∏è"
                print(f"   {status} {user}: {count} –ø—Ä–æ–±–ª–µ–º (–æ—à–∏–±–æ–∫: {user_errors}, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {user_warnings})")
    
    def _generate_recommendations(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π"""
        print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–°–¢–†–ê–ù–ï–ù–ò–Æ:")
        print("-" * 40)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏
        if self.errors_found:
            error_codes = [err['code'] for err in self.errors_found]
            top_errors = Counter(error_codes).most_common(3)
            
            print(f"üîß –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è:")
            for code, count in top_errors:
                error_def = get_error_by_code(code)
                if error_def:
                    print(f"\n   {code} (–≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è {count} —Ä–∞–∑):")
                    print(f"   –ü—Ä–æ–±–ª–µ–º–∞: {error_def.description}")
                    print(f"   –†–µ—à–µ–Ω–∏–µ: {error_def.solution}")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        if self.warnings_found and self.include_warnings:
            warning_codes = [warn['code'] for warn in self.warnings_found]
            top_warnings = Counter(warning_codes).most_common(3)
            
            print(f"\n‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–ª—è –≤–Ω–∏–º–∞–Ω–∏—è:")
            for code, count in top_warnings:
                if code.startswith('PYTHON_'):
                    warning_type = code.replace('PYTHON_', '').lower()
                    print(f"\n   {code} (–≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è {count} —Ä–∞–∑):")
                    print(f"   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –û–±–Ω–æ–≤–∏—Ç–µ –∫–æ–¥ –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è {warning_type} –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π")
                else:
                    warning_def = get_error_by_code(code)
                    if warning_def:
                        print(f"\n   {code} (–≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è {count} —Ä–∞–∑):")
                        print(f"   –ü—Ä–æ–±–ª–µ–º–∞: {warning_def.description}")
                        print(f"   –†–µ—à–µ–Ω–∏–µ: {warning_def.solution}")
        
        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        categories = defaultdict(int)
        for error in self.errors_found:
            error_def = get_error_by_code(error['code'])
            if error_def:
                categories[error_def.category.value] += 1
        
        self._generate_category_recommendations(categories)
        
        print(f"\nüîÑ –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print(f"   ‚Ä¢ –ú–∏–≥—Ä–∞—Ü–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∞ —Å –º–µ—Å—Ç–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
        print(f"   ‚Ä¢ –ò—Å–ø—Ä–∞–≤—å—Ç–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –ø–µ—Ä–µ–¥ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º")
        if self.warnings_found:
            print(f"   ‚Ä¢ –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –Ω–µ –±–ª–æ–∫–∏—Ä—É—é—Ç –º–∏–≥—Ä–∞—Ü–∏—é, –Ω–æ —Ç—Ä–µ–±—É—é—Ç –≤–Ω–∏–º–∞–Ω–∏—è")
        print(f"   ‚Ä¢ –£–≤–µ–ª–∏—á—å—Ç–µ —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")
    
    def _generate_category_recommendations(self, categories: Dict[str, int]):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –æ—à–∏–±–æ–∫"""
        if categories.get('MOUNT', 0) > 0:
            print(f"\nüîå –ü—Ä–æ–±–ª–µ–º—ã –º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ({categories['MOUNT']} –æ—à–∏–±–æ–∫):")
            print(f"   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–µ—Ç–µ–≤–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ")
            print(f"   ‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ credentials")
            print(f"   ‚Ä¢ –£–≤–µ–ª–∏—á—å—Ç–µ MOUNT_ATTEMPTS –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        
        if categories.get('TARGET', 0) > 0:
            print(f"\nüíæ –ü—Ä–æ–±–ª–µ–º—ã —Å —Ü–µ–ª–µ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π ({categories['TARGET']} –æ—à–∏–±–æ–∫):")
            print(f"   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–≤–æ–±–æ–¥–Ω–æ–µ –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ")
            print(f"   ‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –Ω–∞–ª–∏—á–∏–∏ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞")
            print(f"   ‚Ä¢ –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç —Å –ø—Ä–∞–≤–∞–º–∏ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞")
        
        if categories.get('COPY', 0) > 0:
            print(f"\nüìÅ –ü—Ä–æ–±–ª–µ–º—ã –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è ({categories['COPY']} –æ—à–∏–±–æ–∫):")
            print(f"   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
            print(f"   ‚Ä¢ –û—Å–≤–æ–±–æ–¥–∏—Ç–µ –º–µ—Å—Ç–æ –Ω–∞ —Ü–µ–ª–µ–≤–æ–º –¥–∏—Å–∫–µ")
            print(f"   ‚Ä¢ –ó–∞–∫—Ä–æ–π—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –±–ª–æ–∫–∏—Ä—É—é—â–∏–µ —Ñ–∞–π–ª—ã")
        
        if categories.get('USER', 0) > 0:
            print(f"\nüë§ –ü—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏ ({categories['USER']} –æ—à–∏–±–æ–∫):")
            print(f"   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
            print(f"   ‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å –≤ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –∏–º–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
            print(f"   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–æ–º–µ–Ω–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫")
        
        if categories.get('NETWORK', 0) > 0:
            print(f"\nüåê –°–µ—Ç–µ–≤—ã–µ –ø—Ä–æ–±–ª–µ–º—ã ({categories['NETWORK']} –æ—à–∏–±–æ–∫):")
            print(f"   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Å–µ—Ç–µ–≤–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è")
            print(f"   ‚Ä¢ –£–≤–µ–ª–∏—á—å—Ç–µ —Ç–∞–π–º–∞—É—Ç—ã –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            print(f"   ‚Ä¢ –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è")


def main():
    parser = argparse.ArgumentParser(description="–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö")
    parser.add_argument('--log-file', '-l', 
                       default='/var/log/migration_log_*.log',
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –ª–æ–≥–æ–≤ –º–∏–≥—Ä–∞—Ü–∏–∏')
    parser.add_argument('--state-file', '-s',
                       default='/var/lib/migration-service/state.json',
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏')
    parser.add_argument('--no-warnings', action='store_true',
                       help='–ù–µ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è')
    parser.add_argument('--summary-only', action='store_true',
                       help='–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É')
    parser.add_argument('--export-json', 
                       help='–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON —Ñ–∞–π–ª')
    
    args = parser.parse_args()
    
    analyzer = MigrationErrorAnalyzer(include_warnings=not args.no_warnings)
    
    print("üîç –ê–ù–ê–õ–ò–ó–ê–¢–û–† –û–®–ò–ë–û–ö –ò –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ô –ú–ò–ì–†–ê–¶–ò–ò")
    print("=" * 50)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
    if Path(args.log_file).exists():
        analyzer.analyze_log_file(args.log_file)
    else:
        # –ò—â–µ–º —Ñ–∞–π–ª—ã –ª–æ–≥–æ–≤ –ø–æ –º–∞—Å–∫–µ
        log_files = list(Path('/var/log').glob('migration_log_*.log'))
        if log_files:
            latest_log = max(log_files, key=lambda p: p.stat().st_mtime)
            analyzer.analyze_log_file(str(latest_log))
        else:
            print(f"‚ö†Ô∏è  –§–∞–π–ª—ã –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    if Path(args.state_file).exists():
        analyzer.analyze_state_file(args.state_file)
    else:
        print(f"‚ö†Ô∏è  –§–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.state_file}")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    analyzer.generate_report()
    
    # –≠–∫—Å–ø–æ—Ä—Ç –≤ JSON –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω
    if args.export_json:
        export_data = {
            'errors': analyzer.errors_found,
            'warnings': analyzer.warnings_found if analyzer.include_warnings else [],
            'analysis_timestamp': datetime.now().isoformat(),
            'total_errors': len(analyzer.errors_found),
            'total_warnings': len(analyzer.warnings_found) if analyzer.include_warnings else 0
        }
        
        with open(args.export_json, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤: {args.export_json}")


if __name__ == "__main__":
    main()